{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOt+LrnBbFVSVvvBsYIvwvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srivanitadaka/AI--Customer-Support-Quality-Auditor/blob/main/Transcribe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJuzBG_Mtmqs",
        "outputId": "d6290bdc-99a3-444a-d136-09e7f61b9983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wq0b1flw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-wq0b1flw\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.9.0+cu128)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (4.67.3)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.13.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803980 sha256=45bc4415c4d2781c739659bbc13dd1cf0bc8e11efd794e1c4f19fee6300fa8b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-razg70u_/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,361 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,298 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,708 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,468 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,040 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,729 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,678 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,609 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,895 kB]\n",
            "Fetched 39.3 MB in 3s (12.8 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "43 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 43 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"call log 1.m4a\" --model base.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrJq5L-durjd",
        "outputId": "5c95530d-42c9-45d4-bac6-fbdc9d43fc7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:13<00:00, 10.7MiB/s]\n",
            "[00:00.000 --> 00:11.000]  Thank you for calling Nissan. My name is Lauren. Can I have your name?\n",
            "[00:11.000 --> 00:13.000]  Yeah, my name is John Smith.\n",
            "[00:13.000 --> 00:16.000]  Thank you, John. How can I help you?\n",
            "[00:16.000 --> 00:20.000]  I was just calling about to see how much it would cost to update the map in my car.\n",
            "[00:20.000 --> 00:24.000]  I'd be happy to help you with that today. Did you receive a mailer from us?\n",
            "[00:24.000 --> 00:26.000]  I did. Do you need the customer number?\n",
            "[00:26.000 --> 00:30.000]  Yes, please. Okay. It's 1524-3.\n",
            "[00:30.000 --> 00:33.000]  Thank you. And the year making model of your vehicle?\n",
            "[00:33.000 --> 00:37.000]  Yeah, I have a 2009 Nissan Altima.\n",
            "[00:37.000 --> 00:38.000]  Oh, nice car.\n",
            "[00:38.000 --> 00:40.000]  Yeah. Thank you. We really enjoy it.\n",
            "[00:40.000 --> 00:46.000]  Okay. I think I found your profile here. Can I have you verify your address and phone number, please?\n",
            "[00:46.000 --> 00:53.000]  Yes. It's 1255 North Research Way. That's an ORM Utah 84097.\n",
            "[00:53.000 --> 00:58.000]  And my phone number is A01-431-1000.\n",
            "[00:58.000 --> 01:01.000]  Thanks, John. I located your information.\n",
            "[01:01.000 --> 01:08.000]  The newest version we have available for your vehicle is version 7.7, which was released in March of 2012.\n",
            "[01:08.000 --> 01:12.000]  The price of the new map is $99 plus shipping and tax.\n",
            "[01:12.000 --> 01:15.000]  Let me go ahead and set up this order for you.\n",
            "[01:15.000 --> 01:19.000]  Well, can we wait just a second? I'm not really sure if I can afford it right now.\n",
            "[01:19.000 --> 01:23.000]  All right. Well, here are a few reasons to consider purchasing today.\n",
            "[01:23.000 --> 01:27.000]  It looks as though you haven't updated your vehicle for three years.\n",
            "[01:27.000 --> 01:31.000]  So that would be the equivalent of getting three years' worth of updates for the price of one.\n",
            "[01:31.000 --> 01:32.000]  Oh, okay.\n",
            "[01:32.000 --> 01:37.000]  In addition, special offers like the current promotion don't come around too often.\n",
            "[01:37.000 --> 01:42.000]  I would definitely recommend taking advantage of the extra $50 off before it expires.\n",
            "[01:42.000 --> 01:44.000]  Yeah, that does sound pretty good.\n",
            "[01:44.000 --> 01:49.000]  If I set this order up for you now, it'll ship out today and for $50 less.\n",
            "[01:49.000 --> 01:53.000]  Do you have your credit card handy and I can place this order for you now?\n",
            "[01:53.000 --> 01:57.000]  Yeah, let's go ahead and use a visa.\n",
            "[01:57.000 --> 01:59.000]  My number is...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"call log 2.m4a\" --model base.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFcNZU_owYmF",
        "outputId": "d81b4bcd-ced5-4705-95de-230a83cfe616"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:04.000]  Thank you for calling Martha's Flourist, how necessary.\n",
            "[00:04.000 --> 00:08.000]  Hello, I'd like to order flowers, and I think you have what I'm looking for.\n",
            "[00:08.000 --> 00:11.000]  I'd be happy to take care of your order. May I have your name, please?\n",
            "[00:11.000 --> 00:13.000]  Randall Thomas.\n",
            "[00:13.000 --> 00:16.000]  Randall Thomas, can you spell that for me?\n",
            "[00:16.000 --> 00:19.000]  Randall, R-A-N-B-A-L-L.\n",
            "[00:19.000 --> 00:23.000]  Thomas, D-H-O-N-N.\n",
            "[00:23.000 --> 00:27.000]  Thank you for that information, Randall. May I have your home or office number area code first?\n",
            "[00:27.000 --> 00:34.000]  E-R-C-O-4-09, then 5-866-5088.\n",
            "[00:34.000 --> 00:41.000]  That's 4-0-9-866-5088. Do you have a fax number or email address?\n",
            "[00:41.000 --> 00:47.000]  Email is trandall.com or at gmail.com.\n",
            "[00:47.000 --> 00:52.000]  Randall.thomas at gmail.com. May I have your shipping address?\n",
            "[00:52.000 --> 00:53.000]  6800.\n",
            "[00:53.000 --> 00:54.000]  Okay.\n",
            "[00:54.000 --> 01:01.000]  Gladys Avenue, home on Texas, zip code 8, 77706.\n",
            "[01:01.000 --> 01:08.000]  Gladys Avenue, Beaumont, Texas, zip code 77706. Thank you for the information.\n",
            "[01:08.000 --> 01:11.000]  What products are you interested in purchasing?\n",
            "[01:11.000 --> 01:14.000]  Red roses, probably a dozen.\n",
            "[01:14.000 --> 01:17.000]  One dozen of red roses, do you want long stems?\n",
            "[01:17.000 --> 01:18.000]  They're sure.\n",
            "[01:18.000 --> 01:22.000]  All right, Randall, let me process the order. One moment, please.\n",
            "[01:22.000 --> 01:24.000]  Okay.\n",
            "[01:24.000 --> 01:30.000]  Randall, you're ordering one dozen long-stent red roses, the total amount of your order is $40,\n",
            "[01:30.000 --> 01:34.000]  and it will be shipped to your address within 24 hours.\n",
            "[01:34.000 --> 01:37.000]  I was looking to deliver my roses again.\n",
            "[01:37.000 --> 01:39.000]  Within 24 hours?\n",
            "[01:39.000 --> 01:40.000]  Okay, no problem.\n",
            "[01:40.000 --> 01:42.000]  Is there anything else I can help you with?\n",
            "[01:42.000 --> 01:44.000]  That's all for now, thanks.\n",
            "[01:44.000 --> 01:48.000]  No problem, Randall. Thank you for calling Martha's Flourist. Have a nice day.\n",
            "[01:52.000 --> 01:55.000]  Thank you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_xSJmab2xSsx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}